{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f395e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='can you add 2 and 30, please?', additional_kwargs={}, response_metadata={}, id='a0ff2120-91e9-44ed-a17d-00073b033685'), AIMessage(content='2 + 30 = 32', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 46, 'total_tokens': 54, 'completion_time': 0.002070092, 'prompt_time': 0.011436672, 'queue_time': 0.001603759, 'total_time': 0.013506764}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2477e04561', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--6a60b6cc-0ef9-4bba-b9f7-5bda29a79007-0', usage_metadata={'input_tokens': 46, 'output_tokens': 8, 'total_tokens': 54})]}\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph import graph\n",
    "from typing_extensions import TypedDict, List\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_tavily import TavilySearch\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MultiToolState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0)\n",
    "\n",
    "internet_search_tool = TavilySearch()\n",
    "\n",
    "def add(a:int, b:int) -> int:\n",
    "    \"\"\"Adds two numbers.\n",
    "\n",
    "    Args:\n",
    "        a (int): The first number.\n",
    "        b (int): The second number.\n",
    "\n",
    "    Returns:\n",
    "        int: The sum of the two numbers.\n",
    "    \"\"\"\n",
    "    return a + b    \n",
    "\n",
    "def multiply(a:int, b:int) -> int:\n",
    "    \"\"\"Multiplies two numbers.\n",
    "\n",
    "    Args:\n",
    "        a (int): The first number.\n",
    "        b (int): The second number.\n",
    "\n",
    "    Returns:\n",
    "        int: The product of the two numbers.\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [internet_search_tool, add, multiply]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def superbot(state: MultiToolState):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder = StateGraph(MultiToolState)\n",
    "graph_builder.add_node(\"superbot\", superbot)\n",
    "graph_builder.add_edge(START, \"superbot\")\n",
    "graph_builder.add_edge(\"superbot\", END) \n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "res = graph.invoke({\"messages\": [\"can you add 2 and 30, please?\"]})\n",
    "\n",
    "print(res)\n",
    "\n",
    "#output \n",
    "#{'messages': [HumanMessage(content='can you add 2 and 30, please?', additional_kwargs={}, response_metadata={}, id='a0ff2120-91e9-44ed-a17d-00073b033685'), AIMessage(content='2 + 30 = 32', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 46, 'total_tokens': 54, 'completion_time': 0.002070092, 'prompt_time': 0.011436672, 'queue_time': 0.001603759, 'total_time': 0.013506764}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2477e04561', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--6a60b6cc-0ef9-4bba-b9f7-5bda29a79007-0', usage_metadata={'input_tokens': 46, 'output_tokens': 8, 'total_tokens': 54})]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d916eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='can you add 2 and 30, please?', additional_kwargs={}, response_metadata={}, id='f7dfa87c-407e-4e6d-af25-be4e11115a13'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'b5jwn0hkp', 'function': {'arguments': '{\"a\":2,\"b\":30}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 1925, 'total_tokens': 1943, 'completion_time': 0.05078824, 'prompt_time': 0.166654531, 'queue_time': 0.003068357, 'total_time': 0.217442771}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f089a29207', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--2b68b725-3cd5-443f-a8ce-328835100c70-0', tool_calls=[{'name': 'add', 'args': {'a': 2, 'b': 30}, 'id': 'b5jwn0hkp', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1925, 'output_tokens': 18, 'total_tokens': 1943})]}\n"
     ]
    }
   ],
   "source": [
    "def superbot(state: MultiToolState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder = StateGraph(MultiToolState)\n",
    "graph_builder.add_node(\"superbot\", superbot)\n",
    "graph_builder.add_edge(START, \"superbot\")\n",
    "graph_builder.add_edge(\"superbot\", END) \n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "res = graph.invoke({\"messages\": [\"can you add 2 and 30, please?\"]})\n",
    "\n",
    "print(res)\n",
    "\n",
    "#output\n",
    "#{'messages': [HumanMessage(content='can you add 2 and 30, please?', additional_kwargs={}, response_metadata={}, id='82e6eecd-d7ac-46f1-bf2a-a51f35470efc'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'rmwn2k9n8', 'function': {'arguments': '{\"a\":2,\"b\":30}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 1925, 'total_tokens': 1943, 'completion_time': 0.050792134, 'prompt_time': 0.155359789, 'queue_time': 0.068414258, 'total_time': 0.206151923}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_a2c262bc3a', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--acf11271-23f8-4aa1-9248-593420e17c23-0', tool_calls=[{'name': 'add', 'args': {'a': 2, 'b': 30}, 'id': 'rmwn2k9n8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1925, 'output_tokens': 18, 'total_tokens': 1943})]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_chatbot_tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
